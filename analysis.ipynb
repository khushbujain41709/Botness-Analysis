{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9951bfd",
   "metadata": {},
   "source": [
    "1. Loads labeled text data (examples of messages labeled as human, content_bot, follower_bot, etc.).\n",
    "2. Cleans and maps labels to numbers.\n",
    "3.  Splits data into training and test sets.\n",
    "4. Tries three different feature+model approaches:\n",
    "    Character-level n-gram features with XGBoost.\n",
    "    Hand-crafted/custom numeric features with XGBoost.\n",
    "    Word pattern features with a Random Forest.\n",
    "5. Compares accuracies on the test set and saves the best model and its vectorizer/extractor for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640a3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9752ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"text_bot_training.csv\")\n",
    "\n",
    "# Clean data\n",
    "df.dropna(subset=[\"text\", \"label\"], inplace=True)\n",
    "df[\"label\"] = df[\"label\"].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c231c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "label_map = {\n",
    "    \"human\": 0, \n",
    "    \"content_bot\": 1, \n",
    "    \"follower_bot\": 2, \n",
    "    \"spam_bot\": 3, \n",
    "    \"customer_service_bot\": 4\n",
    "}\n",
    "df[\"label\"] = df[\"label\"].map(label_map)\n",
    "df.dropna(subset=[\"label\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b727176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (250, 2)\n",
      "Label distribution:\n",
      "label\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "4    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned data shape:\", df.shape)\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"label\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5daf496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0862a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARACTER-LEVEL FEATURES\n",
      "Character features shape: (200, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\"CHARACTER-LEVEL FEATURES\")\n",
    "char_vectorizer = CountVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5), # Character 3-5 grams\n",
    "    max_features=1000,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "X_train_char = char_vectorizer.fit_transform(X_train)\n",
    "X_test_char = char_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Character features shape: {X_train_char.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fa5908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character-level Accuracy: 0.84\n",
      "Character-level Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               human       1.00      1.00      1.00        10\n",
      "         content_bot       1.00      1.00      1.00        10\n",
      "        follower_bot       0.90      0.90      0.90        10\n",
      "            spam_bot       0.70      0.70      0.70        10\n",
      "customer_service_bot       0.60      0.60      0.60        10\n",
      "\n",
      "            accuracy                           0.84        50\n",
      "           macro avg       0.84      0.84      0.84        50\n",
      "        weighted avg       0.84      0.84      0.84        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\", \n",
    "    num_class=5, \n",
    "    eval_metric=\"mlogloss\", \n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "char_model.fit(X_train_char, y_train)\n",
    "y_pred_char = char_model.predict(X_test_char)\n",
    "print(\"Character-level Accuracy:\", accuracy_score(y_test, y_pred_char))\n",
    "print(\"Character-level Classification Report:\\n\", classification_report(y_test, y_pred_char, target_names=label_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e206ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUSTOM FEATURES\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCUSTOM FEATURES\")\n",
    "def extract_bot_features(texts):\n",
    "    features = []\n",
    "    for text in texts:\n",
    "        text_lower = str(text).lower()\n",
    "        words = text_lower.split()\n",
    "        \n",
    "        feature_dict = {\n",
    "            # Structural features\n",
    "            'text_length': len(text),\n",
    "            'word_count': len(words),\n",
    "            'char_density': len(text) / max(1, len(text.replace(' ', ''))),\n",
    "            \n",
    "            # Bot pattern indicators\n",
    "            'underscore_count': text_lower.count('_'),\n",
    "            'has_underscore': int('_' in text_lower),\n",
    "            'has_http': int('http' in text_lower),\n",
    "            'has_digits': int(any(char.isdigit() for char in text)),\n",
    "            \n",
    "            # Keyword patterns\n",
    "            'bot_keywords': sum(1 for word in words if word in [\n",
    "                'bot', 'auto', 'follow', 'like', 'click', 'free', 'win', 'update', \n",
    "                'news', 'alert', 'offer', 'deal', 'prize', 'boost', 'growth',\n",
    "                'support', 'help', 'service', 'customer', 'tracking', 'order'\n",
    "            ]),\n",
    "            \n",
    "            # Linguistic features\n",
    "            'unique_word_ratio': len(set(words)) / max(1, len(words)),\n",
    "            'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
    "            'uppercase_ratio': sum(1 for char in text if char.isupper()) / max(1, len(text)),\n",
    "            \n",
    "            # Specific bot type indicators\n",
    "            'follower_terms': sum(1 for word in words if word in ['follow', 'follower', 'growth', 'boost', 'like', 'instagram', 'twitter']),\n",
    "            'spam_terms': sum(1 for word in words if word in ['free', 'win', 'prize', 'click', 'offer', 'deal', 'limited']),\n",
    "            'content_terms': sum(1 for word in words if word in ['news', 'update', 'alert', 'trend', 'daily', 'report']),\n",
    "            'service_terms': sum(1 for word in words if word in ['support', 'help', 'service', 'customer', 'order', 'tracking']),\n",
    "        }\n",
    "        features.append(list(feature_dict.values()))\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20237c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom features shape: (200, 15)\n",
      "Custom Features Accuracy: 0.58\n",
      "Custom Features Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               human       1.00      1.00      1.00        10\n",
      "         content_bot       0.46      0.60      0.52        10\n",
      "        follower_bot       0.57      0.40      0.47        10\n",
      "            spam_bot       0.56      0.50      0.53        10\n",
      "customer_service_bot       0.36      0.40      0.38        10\n",
      "\n",
      "            accuracy                           0.58        50\n",
      "           macro avg       0.59      0.58      0.58        50\n",
      "        weighted avg       0.59      0.58      0.58        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_custom = extract_bot_features(X_train)\n",
    "X_test_custom = extract_bot_features(X_test)\n",
    "\n",
    "print(f\"Custom features shape: {X_train_custom.shape}\")\n",
    "\n",
    "custom_model = XGBClassifier(random_state=42)\n",
    "custom_model.fit(X_train_custom, y_train)\n",
    "y_pred_custom = custom_model.predict(X_test_custom)\n",
    "print(\"Custom Features Accuracy:\", accuracy_score(y_test, y_pred_custom))\n",
    "print(\"Custom Features Classification Report:\\n\", classification_report(y_test, y_pred_custom, target_names=label_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41876f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SIMPLE WORD PATTERNS\n",
      "Pattern features shape: (200, 200)\n",
      "Sample pattern features: ['account_assist' 'account_assist password_reset' 'account_transfer'\n",
      " 'account_transfer content_backup' 'account_verification'\n",
      " 'account_verification security_check' 'achievement_badges' 'act_fast'\n",
      " 'act_fast last_chance' 'adventure' 'advertising_profits'\n",
      " 'advertising_profits monetization_strategies' 'afternoon'\n",
      " 'afternoon hiking' 'aggregation_services' 'amazing' 'auto_news_update'\n",
      " 'auto_news_update tech_trends' 'auto_posting'\n",
      " 'auto_posting content_scheduling']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSIMPLE WORD PATTERNS\")\n",
    "pattern_vectorizer = CountVectorizer(\n",
    "    max_features=200,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    token_pattern=r'(?u)\\b[a-z_][a-z_]{2,}\\b'  # Match words with underscores\n",
    ")\n",
    "\n",
    "X_train_pattern = pattern_vectorizer.fit_transform(X_train)\n",
    "X_test_pattern = pattern_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Pattern features shape: {X_train_pattern.shape}\")\n",
    "print(\"Sample pattern features:\", pattern_vectorizer.get_feature_names_out()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0fb33ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern-based Accuracy: 0.3\n",
      "Pattern-based Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               human       1.00      0.50      0.67        10\n",
      "         content_bot       0.00      0.00      0.00        10\n",
      "        follower_bot       0.00      0.00      0.00        10\n",
      "            spam_bot       0.22      1.00      0.36        10\n",
      "customer_service_bot       0.00      0.00      0.00        10\n",
      "\n",
      "            accuracy                           0.30        50\n",
      "           macro avg       0.24      0.30      0.21        50\n",
      "        weighted avg       0.24      0.30      0.21        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khushbu\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\khushbu\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\khushbu\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "pattern_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "pattern_model.fit(X_train_pattern, y_train)\n",
    "y_pred_pattern = pattern_model.predict(X_test_pattern)\n",
    "print(\"Pattern-based Accuracy:\", accuracy_score(y_test, y_pred_pattern))\n",
    "print(\"Pattern-based Classification Report:\\n\", classification_report(y_test, y_pred_pattern, target_names=label_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef79db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using CHARACTER-LEVEL model\n",
      "\n",
      "Best accuracy: 0.840\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Choose the best approach and save\n",
    "best_accuracy = max(\n",
    "    accuracy_score(y_test, y_pred_char),\n",
    "    accuracy_score(y_test, y_pred_custom),\n",
    "    accuracy_score(y_test, y_pred_pattern)\n",
    ")\n",
    "\n",
    "if best_accuracy == accuracy_score(y_test, y_pred_char):\n",
    "    print(\"\\nUsing CHARACTER-LEVEL model\")\n",
    "    joblib.dump(char_model, \"best_model_xgb.pkl\")\n",
    "    joblib.dump(char_vectorizer, \"vectorizer.pkl\")\n",
    "    best_vectorizer = char_vectorizer\n",
    "elif best_accuracy == accuracy_score(y_test, y_pred_custom):\n",
    "    print(\"\\nUsing CUSTOM FEATURES model\")\n",
    "    joblib.dump(custom_model, \"best_model_xgb.pkl\")\n",
    "    # For custom features, we need the feature extraction function\n",
    "    with open(\"feature_extractor.pkl\", \"wb\") as f:\n",
    "        joblib.dump(extract_bot_features, f)\n",
    "    best_vectorizer = None\n",
    "else:\n",
    "    print(\"\\nUsing PATTERN-BASED model\")\n",
    "    joblib.dump(pattern_model, \"best_model_xgb.pkl\")\n",
    "    joblib.dump(pattern_vectorizer, \"vectorizer.pkl\")\n",
    "    best_vectorizer = pattern_vectorizer\n",
    "\n",
    "print(f\"\\nBest accuracy: {best_accuracy:.3f}\")\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
